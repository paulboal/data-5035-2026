{
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter Notebook",
      "name": "jupyter"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "id": "074df485-960d-4cbb-8929-eab14947eadc",
      "metadata": {
        "language": "python",
        "title": "Scrape WashU Events"
      },
      "source": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\n# Fetch HTML from WashU events page\nresponse = requests.get('https://happenings.washu.edu/')\nsoup = BeautifulSoup(response.text, 'html.parser')\n\nevents = []\n\n# Find all event cards and extract data\nfor card in soup.find_all('div', class_='em-card_text'):\n    # Get event name and link from title element\n    title_elem = card.find('h3', class_='em-card_title')\n    name = title_elem.get_text(strip=True) if title_elem else ''\n    link = title_elem.find('a')['href'] if title_elem and title_elem.find('a') else ''\n    \n    # Get date/time and location from event text paragraphs\n    event_texts = card.find_all('p', class_='em-card_event-text')\n    date_time = event_texts[0].get_text(strip=True) if len(event_texts) > 0 else ''\n    location = event_texts[1].get_text(strip=True) if len(event_texts) > 1 else ''\n    \n    if name:\n        events.append({'name': name, 'date_time': date_time, 'location': location, 'link': link})\n\n# Create DataFrame from extracted events\ndf = pd.DataFrame(events)\nprint(f\"Found {len(df)} events\")\ndf",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "28f8c759-20fc-4bfe-a378-d229099e2ae4",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "",
      "outputs": [],
      "execution_count": null
    }
  ]
}